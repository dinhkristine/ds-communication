\documentclass[11pt]{article}

\usepackage{rotating}
\usepackage{graphics}
\usepackage{latexsym}
\usepackage{color}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[belowskip=-15pt,aboveskip=0pt]{caption}

\setlength\topmargin{-.56in}
\setlength\evensidemargin{0in}
\setlength\oddsidemargin{0in}
\setlength\textwidth{6.49in}
\setlength\textheight{8.6in}
\setlength{\intextsep}{10pt plus 1pt minus 4pt}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}
\lstset{style=mystyle}

\pagestyle{headings}

\title{Statistical Analysis and Predictive Models for Expenditures in New York Municipalities\vspace{-5ex}} 
\date{October 08, 2020\vspace{-5ex}}

\begin{document} 
\maketitle
\hfill \break

<<packages, echo=FALSE, warning=FALSE, message=FALSE>>=

library(tidyverse)
library(magrittr)
library(ggcorrplot)
library(MASS)
library(leaps)
library(car)
library(stargazer)
library(gridExtra)
library(broom)
library(knitr)
library(kableExtra)

@

<<parameter and functions, echo=FALSE>>=

#### Parameters ####
my_col <- "#5a8fa1"

#### Functions ####
ScatterPlotFunction <- function(df, xvar, xlab, smooth_method = "loess"){
  ggplot(df, aes_string(x = xvar, y = "lexpen")) + 
    geom_point(size = 2, alpha = 0.4) + 
    geom_smooth(method = smooth_method, se = FALSE, color = "red", size = 1) + 
    theme_minimal() + 
    labs(y = "Log-Expenditures", 
         x = xlab)
}

ValidationTable <- function(fit){
  mod <- fit
  fit_summary <- tibble(Features = paste0((coef(mod) %>% names())[-1], collapse = ", "), 
                        MSE = mean(mod$residuals^2), 
                        Adj.R.squared = summary(mod)$adj.r.squared, 
                        F.statistics = summary(mod)$fstatistic[[1]], 
                        AIC = AIC(mod))
  return(fit_summary)
}

@

<<load data, echo=FALSE, warning=FALSE, message=FALSE>>=

setwd(here::here())

ny <- read.table("data/cs73.dat", header = T)

ny2 <- na.omit(ny)

#### Add transformed variables ####
ny2 %<>% 
  mutate(lexpen = log(expen), 
         lwealth = log(wealth), 
         lpop = log(pop), 
         lpint = log(pint), 
         ldens = log(dens), 
         lincome = log(income), 
         lgrowr = case_when(
           growr > 0 ~ log(growr + 1.01), 
           TRUE ~ -log(-growr + 1.01)))

@


\noindent\textbf{Executive Summary} 

\noindent In New York, there are many new housing projects started daily. Given the issue that the town need to generate more funds through property tax when expenditures increases. However, there is no clear understanding of what factors cause the expenses to increase/descreases. Therefore, a clear goal for this analysis is to find variables that effect expenditures. A tool was developed using a multiple linear regression model to predict expenditures using a dataset from the New York municipalities from 1992. With an adjusted R-square of 61\%, a final model was chosen after stepwise variables selection using AIC, MSE, and adjusted R-square criterias. The variables in the model includes population, wealth, income, percent intergorvernment funds, and growth rate. Diagnostics measurements was also ran to check for the quality of the model. Some interesting findings include a 4\% increase in expenditures while wealth increases by 10\%. On the other hand, there will be a 3\% decrease in expenditures while the percentage of intergovernmnetal funds increases by 10\%. Knowing the changes in expenditures caused by wealth, population, intergovernmental funds, and growth rate, construction workers and properties own would be more caution when starting a new project.            
\hfill \break

\noindent\textbf{Introduction} 

\noindent Generally, construction companies have numerous aspects in estimating the cost of each new housing project. To estimate the cost of each housing project, expenditures play an important role in increasing or decreasing the cost. For example, higher expenditure would result in an increase in cost of construction. Therefore, the property owners would have to seek for higher funding to fulfill the project. On the other hand, while expenditure decreases, propertyâ€™s owner could spend the reimburse the expenses elsewhere. In addition, knowing the expenditures would also help construction manager to order supplies in a proper manger. If expenditure decreases, then the supplies would also be less in quantity or cheaper in quality. Numerous questions were proposed in favor of these issues such as 1) What variables causes the fluctuation of expenditure? 2) What is the best predictive model that could predict expenditures? 3) How can we validate and implement the model? 3) How accurate is the model? 4) Is there any improvement to the future models? To answer these questions, this analysis will take a deep dive into the data exploratory analysis, model development process using linear regression, and diagnostics analysis. With the answered questions, construction workers and properties owner would have a better understanding of their expenditures when starting a new project to avoid over or underestimating their budgets.
\hfill \break

\noindent\textbf{Methods} 

\noindent A dataset from two New York municipalities (Warwick and Monroe) were provided to access the important measures to predict expenditures. These data contain a total of \Sexpr{nrow(ny)} observations from 1992 with \Sexpr{is.na(ny$expen) %>% sum} observation contains missing expenditure value. Two observation with NA expenditures have been removed from the analysis to improve the assumption of linear regression modeling. In terms of variables, this dataset contains three identifiers including identity number, state code, and county code and six demographic and income-related variables including wealth per person, population, percent intergovernmental, density, mean income per person, and growth rate. There is a total of \Sexpr{ny$co %>% unique %>% length} distinct county code implying there are multiple measurement of expenditure per county in New York. The goal of this data analysis is to predict the chances in expenditures of two New York municipalities, Warwick and Monroe. A projection dataset for Warwick and Monroe was also provided to generate predictions from using the fitted model. To achieve this goal, all analysis will be done using multiple linear regression models for model development process and accompany by diagnostics process to check for the quality of the model. All analysis including coding and writing report is done in R Studio with R version 3.6.2.    
\hfill \break

\noindent\textbf{Exploratory Data Analysis} 

\noindent During the exploratory analysis process, it is important to access all the significant relationship of each variable with the target variable. Initially, looking at Table~\ref{descrips}, the summary statistics of all independent variables and target variable shows the maximum for expenditures, wealth, population, pint, density, income, and growth rate are extremely high compare to their mean and 75 percentiles. This indicates that all the variables mention previous are heavily right skewed. Most importantly, expenditure's skewness violates the normality assumption when generating a linear regression. Therefore, a log transformation was applied to expenditure to normalize the distribution of the target variable. Log-transformation would reduce the values which would account for outliers. Figure~\ref{inital-explore}.1. depicts the normality of the outcome variable expenditure after transformation implying the assumption is not violated.

\begin{figure}[h!] 
\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.width=10, fig.height=3>>=

p1 <- ggplot(ny2, aes(lexpen)) + 
  geom_histogram(bins = 30, col = "dark gray", fill = my_col) +
  theme_minimal() + 
  labs(x = "Log-Expenditures", 
       y = "Count")

p2 <- ScatterPlotFunction(ny2, "lpop", "Log-Population")

p3 <- ScatterPlotFunction(ny2, "ldens", "Log-Density")

grid.arrange(p1, p2, p3, nrow = 1, ncol = 3)

@
\caption{Initial Exploratory Plots after Log-Transformation 1: Histogram of Log-Expenditures with Frequency, 2: Scatter plot of Log-Expenditures vs Log-Population with LOESS smooth line in red, and 3: Scatterplot of Log-Expenditures vs Log-Density with LOESS smooth line in red.}
\label{inital-explore}
\end{center} 
\end{figure}

\noindent Since all independent variable are right-skewed, a log-transformation also applied to each variable to ensure linear relationship with expenditures. An amount of 1.01 was added to all growth rate values to account for zeros values while taking logarithm. All variables mentioned in the rest of this article are log-transformed variables unless otherwise specified. With that being said, wealth, intergovernmental funds, income, and grow rate seems to have linear relationship with expenditures. However, population and density have different two different trend of expenditures within their plots. Figure~\ref{inital-explore}.2. shows a scatterplot of expenditures and population with a dip at approximately 8.3 to change direction of correlation. Population is self-explanatory variable which represent the number of people living in the county during the year. While population is less than 8.3, as population increases, expenditures decrease on average. When population is greater than 8.3, expenditures increase as population increases. Similar issue happens to density at 4.5, see Figure~\ref{inital-explore}.3. Density, here, represent the population of other substances like animals, environment, or other objects. To account for this problem, the data set of New York city will be subsetted into different groups according to each trend. Subsetting data will help the relationship between density and population and expenditures be linear. This analysis will only model data when population is greater than 8.3 and density is greater than 4.5 since the projection data is within these ranges.    
\hfill \break

<<echo = FALSE>>=

#### Subset data ####
## subsetting the data based on regions of log-population and log-density 
## where the relationship with log-expenditure is linear
set2 <- ny2 %>% 
  filter(lpop > 8.3 & ldens > 4.5)

@

\noindent After selecting a subset of data, only \Sexpr{nrow(set2)} observations are left in the data. A second round of data exploratory was conducted to ensure the relationship of each measure if significant to the outcome variable expenditures. Expenditures and wealth have a positive relationship indicating the increases of wealth would cause expenditure to be higher, see Figure~\ref{sec-explore}.1. Intuitively, this makes sense since wealthier individuals would spend more resulting in higher expenses. Similarly, Figure~\ref{sec-explore}.2. shows a strong positive correlation between expenditure and income. This relationship is expected since the mean income per person is higher, their expenses would also be higher compared to lower income individuals. Other variables like population and density seem to have moderate positive relationship with expenditure, see the first two plots in Figure~A\ref{sec2-explore}. Clearly, population and density are important measurements to predict expenditures. As population and density increases, the amount of expenses also increases, on average. On the other hand, predictors including intergovernmental funds and growth rate have moderate negative correlation with expenditures. This indicate that, while intergovernmental funds and growth rate increases, the amount of expenses should decrease. This makes perfect sense since if the growth rate in economic is slow, then there would be lower expenses.             

\begin{figure}[h!] 
\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.width=10, fig.height=3>>=

## use scatterplot to explore the relationship between 
## x and y again with new set 

p1 <- ScatterPlotFunction(set2, "lwealth", "Log-Wealth", "lm")
p2 <- ScatterPlotFunction(set2, "lincome", "Log-Income", "lm")

## correlation plot ##
corr_table <- set2 %>% 
  dplyr::select(lwealth, lpop, lpint, ldens, lincome, lgrowr) %>% 
  cor()

## lpop and ldens have high positive correlation = multicolinary problem 
## lincome and lwealth has high possitive correlation also 
p3 <- ggcorrplot(corr_table, hc.order = TRUE, 
                 outline.col = "white",
                 colors = c(my_col, "white", "red"), type = "upper")

grid.arrange(p1, p2, p3, nrow = 1, ncol = 3)

@
\caption{Exploratory Plot after Log-Transformation and Subsetted Data 1: Scatterplot of Log-Expenditures vs Log-Wealth with Linear Regression line in red, 2: Scatterplot of Log-Expenditures vs Log-Income with linear regression line in red, and 3: Upper Correlation plot of all independent variables.}
\label{sec-explore}
\end{center} 
\end{figure}

\noindent After detecting the relationship of each independent variables with expenditures, it is important to examine the correlation of each predictors. Higher correlation between predictors mean there might be multicollinearity issues when including both variables in the model. This leads the model to have unstable and unreliable coefficients. Figure~\ref{sec-explore}.3. shows the upper diagonal of the correlation matrix plot. As one can see, density and population have a high positive correlation of \Sexpr{round(cor(set2$ldens, set2$lpop), 2)}. To solve the multicollinearity issues, separate models with density in one and population in other, along with other variables, were generated. The results of the models will be compared and selected as the best model. Furthermore, wealth and income also have high positive correlation of \Sexpr{round(cor(set2$lincome, set2$lwealth), 2)}. However, wealth and income are not strongly correlated. Other variables not mentioned above have little to no relationship with expenditures.          
\hfill \break

\noindent\textbf{Statistical Analysis}

<<echo = FALSE>>=

fit1 <- lm(lexpen ~ lwealth + lpint + ldens + lincome + lgrowr, data = set2)

fit2 <- lm(lexpen ~ lwealth + lpop + lpint + lincome + lgrowr, data = set2)

fit3 <- lm(lexpen ~ .*., 
           data = set2 %>% 
             dplyr::select(lexpen, lwealth, lpop, lpint, lincome, lgrowr))

fit4 <- stepAIC(fit3, trace = FALSE)

## create table of validation metrics to compare  
fit1_summary <- ValidationTable(fit1)
fit2_summary <- ValidationTable(fit2)
fit3_summary <- ValidationTable(fit3)
fit4_summary <- ValidationTable(fit4)

fit_final <- fit2

@

\noindent Model selection is a crutial step in a data analysis. A multiple linear regression will be used to build the model. After the exploratory data analysis, there are six possible variables that can be include in the model including wealth, population, percent intergovernmental funds, density, income, and growth rate. As mentioned before, if population and density are in the same models, multicolinearity issues will occur. Therefore, two initial models will be built to compared using three validation metrics such as Akaike information criterion (AIC), R-squared adjusted, and mean square error (MSE). In this case, the ideal best model would have smaller AIC score, higher R-square adjusted, and lower MSE. After building both models, a table of model comparison was generated to select the best model among the two, see Table~B\ref{reg_vali_metric}. This table clearly state that the second model with predictors wealth, population, percent intergovernment funds, income, and grow is the best model with lower MSE and AIC values, and higher R-square adjusted proportion of \Sexpr{round(mean(fit2$residuals^2), 2)}, \Sexpr{round(AIC(fit2), 2)}, and \Sexpr{round(summary(fit2)$adj.r.squared, 2)}, respectively.

\noindent After finding the best predictors for the model (wealth, population, percent intergovernment, income, and growth rate), a stepwise selection was generated for variables selection using AIC values. Unfortunately, stepwise variable selection was not showing any other significant models beside the full model. Furthermore, each combination of the interaction predictors was taken into consideration to find a better model. Results of MSE, R-square adjusted, and AIC for the model with interaction terms (model 3 in Table~B\ref{reg_vali_metric}) are clearly better than model 2. Thus, a stepwise selection method was applied to select the best variables and results is shown in Table~B\ref{reg_vali_metric}) as model 4. Model 4 has the best R-squared adjusted due to the more varivale contain in the model. However, in terms of the model's quality, model 4 seems to have insignicant predictors including welath and wealth times population, see p-value column in Table~B\ref{reg_summary_4}). In addition, the coefficient for percent intergorvenmental funds was expected to be negative as shown in Figure~A\ref{sec2-explore}). These two reasons prove that model 4 with interaction term is not the best model. Therefore, the model with predictors wealth, population, intergovernmental funds, income, and growth rate will be used as the final model.

\noindent After variable selection, diagnostics process is a must to check for the quality of the model. Figure~\ref{diag-plot1}.1. shows the studentized residuals majority are with in the range of -2.5 to 2.5 except one observation 893. This indicates that is observation is an outlier. In addition, Figure~\ref{diag-plot1}.2. shows the cook's distance of all the observations and found that there are a few observation did not made the cutoff point for influential values including 60, 83, 100, 179, and 225. As seen in Table~A\ref{outlier_obs}, outliers and influential points have high values of either expenditures or one of the predictors. However, none of the outliers and influential points were removed because there is no good reasons. Last but not least, the right plot in Figure~\ref{diag-plot1}.3. shows that studentized residuals follow a normal distribution implying the error terms are constant.    

\begin{figure}[h!] 
\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.width=10, fig.height=3>>=

## Residuals
## add prediction values and rstudent residuals into set2 
set2 %<>% 
  mutate(predict = predict(fit_final), 
         rstudent = rstudent(fit_final))

## plot studenttized residuals vs predicted values 
p1 <- ggplot(set2, aes(x = predict, y = rstudent)) + 
  geom_point(size = 2, alpha = .6) + 
  theme_minimal() + 
  labs(x = "Predicted", 
       y = "Studentized Residuals")

## Influential Observations
## Cook's D plot
## identify D values > 4/(n-p-1) as a guide; 
## Cook and Weisberg recommend 0.5 and 1 (R uses these guides in default diagnostic plots below)
cutoff <- 4/((nrow(set2) - length(fit_final$coefficients) - 2))

diag <- broom::augment(fit_final) %>% mutate(Index = 1:nrow(.))

diag %<>% 
  mutate(high_cooksd = case_when(
    .cooksd > cutoff ~ 1, TRUE ~ 0), 
    col_stdresid = case_when(
      .std.resid > 0 ~ 1, 
      .std.resid < 0 ~ 0), 
    high_hat = case_when(
      .hat > .1 ~ 1, 
      TRUE ~ 0))

## cook's distant ggplot
p2 <- ggplot(diag, aes(x = Index, y = .cooksd)) + 
  geom_bar(stat = "identity", fill = my_col) +
  labs(y = "Cook's Distance") + 
  theme_minimal() +  
  geom_label(data = diag %>% filter(.cooksd > cutoff + .03), 
             aes(label = Index), label.size = NA, size = 3)

## Normality of Residuals
set2 %<>% 
  mutate(dnorm_rstudent = dnorm(rstudent))

p3 <- ggplot(set2, aes(x = rstudent)) + 
  geom_histogram(bins = 30, col = "dark gray", fill = my_col) + 
  theme_minimal() + 
  labs(x = "Studentized Residuals", 
       y = "Count")

grid.arrange(p1, p2, p3, nrow = 1, ncol = 3)

@
\caption{Diagnostic plots of 1: Studentized Residuals vs Predicted values, 2: Cook's distance for each observation, and 3: Distribution of studentized residuals}
\label{diag-plot1}
\end{center} 
\end{figure}

\noindent After accessing the quality of the model, an interpretation and explaination of the model will be explained. The summary of regression for the final model (wealth, population, intergovernmental, income, and growth rate) is in Table~\ref{reg_summary_final}. VIF values are all before 3 indicating there is no multicolinearity problem in the model. Confident intervals for majority of coefficients do not contain zeros and small p-values implying all variables are statistically significant in the model. For the purpose of intergrepting, the coefficient will be backtransformation. This means that as wealth, population, or income increases by 10\%, holding all else constant, expenditures will increase by 4\%, 1\%, or 2\%, on average, respectively. On the other hand, while percent intergovernmental fund or growth rate increases by 10\%, on average, expenditures will decrease by 3\% or 1\%, respectively. In addition, this model has an adjusted R-square of \Sexpr{round(summary(fit_final)$adj.r.squared, 2)} indicating that \Sexpr{round(summary(fit_final)$adj.r.squared, 2)*100}\% of the variation in expenditure can be explained by wealth, population, intergovermental, income, and growth rate.   

\begin{center}
<<echo = FALSE, results='asis'>>=

fit_final_table <- fit_final %>% 
  tidy %>% 
  mutate("10% Coef" = 1.1^estimate) %>% 
  cbind(confint(fit_final)) %>% 
  cbind(vif(fit_final) %>% 
          as.data.frame() %>% 
          t() %>% 
          as_tibble() %>% 
          add_column(`(Intercept)` = NA, .before = "lwealth") %>% 
          t() %>% 
          as.data.frame() %>% 
          rename(VIF = V1)) %>% 
  xtable(caption = "Summary Regression of Model 4", 
         label = "reg_summary_final",
         table.placement="H", 
         digits = 4)

print(fit_final_table, include.rownames=FALSE)
  
@
\end{center}

\noindent Given a good model, the goal of this analysis is to predict expenditures for two New York municipalities Warwick and Monroe. A project table of values for predictors was provided for years 1992, 2005, and 2025. Table~\ref{pred_tab} shows a prediction table of the two towns. The values for expenditures seem to be within the range of expenditures in the training set. Looking closely at the projection table, predicted expenditures are higher, on average, in Monroe than Warwick due to the extremenly lower percentage of intergovernmental funds and relatively lower growth rate. According to the model, having lower intergovernmental funds and growth rate leads to higher expenditures. Although, Warwick town has relatively higher population, wealth, and income, on average, Monroe town would still have higher expenditures. The last two columns depicts lower and upper 95\% confident interval of predicted values and we can say that expenditures are confident to be inside these ranges. Given the coeffients being fixed, Warwick and Monroe would expect their expenditures to change if their wealth, population, percent intergovernmental, income, and growth rate change.    

\begin{center}
<<echo = FALSE, results='asis', message=FALSE, warning=FALSE, error = FALSE>>=

#### Predictions

## Account for sigma^2
sd_fit <- sd(fit_final$resid)

## Read Warick and monroe data 
setwd(here::here())
wm <- readxl::read_xlsx("data/warwick-and-monroe.xlsx")

## create log transformation variables for wm
wm %<>% 
  mutate(lwealth = log(wealth), 
         lpop = log(pop), 
         lpint = log(pint), 
         ldens = log(dens), 
         lincome = log(income), 
         lgrowr = case_when(
           growr > 0 ~ log(growr + 1.01), 
           TRUE ~ -log(-growr + 1.01)))


## generate prediction for wm 
wm$lexpen_pred <- predict(fit_final, newdata = wm)

wm %<>%
  mutate(lexpen_pred = predict(fit_final, newdata = wm)) 

wm %<>% 
  cbind(exp(predict(fit_final, wm, interval="prediction") + sd_fit^2/2))

## select col to show 

wm_tab <- wm %>% 
  dplyr::select(town, year, pop, wealth, pint, income, growr, 
                expen_hat = fit, expen_lci = lwr, expen_uci = upr) %>% 
  xtable(caption = "Prediction tables of two cities in New York (Warwick and Monroe)", 
         label = "pred_tab",
         table.placement="H", 
         digits = 1)

print(wm_tab, include.rownames=FALSE)

@
\end{center}

\noindent\textbf{Conclusion}

\noindent In conclusion, expenditures are one of the most important aspects to known before starting a new construction project. It is difficult to estimate expenditures manually. Therefore, this analysis created a tool to automate the process of estimating expenditures. The variables that cause the flunctuation of expenditures are popluation, wealth, percent intergovernmental funds, income, and growth rate. With this model, construction managers and property owners would have a clear understanding of how much funding they would need for a certain type of project in the city. Using the summary regresssion results of our model, it is confident to say that an area with higher population would cause expenditures to be higher. Similarly, if the average of wealth and income is higher, then expenditures will also be higher. However, it is clear that if the percentage of intergovernment funds is lower and growth rate in the city is slower, then expenditures is obviously higher. As a results, this model does not only provide an estimate of expenditures faster, but construction workers can also have a great understanding of what cuase the expenses to shift up and down.

\noindent There are a few limitations in this analysis. This model only use a subset of the main data which is \Sexpr{nrow(set2) / nrow(ny2)} less compared to the full dataset. Therefore, smaller sample size would lead the model to perform not as accurate. Second, growth rate have a small correlation with expenditures indicating the amount the changes in expenditures would be very small if the values of growth rate change. Last but not least, the model is only limited to when population is greater than \Sexpr{exp(8.3)}. Cities with population smaller than \Sexpr{exp(8.3)} cannot use this model. For future reference, there are many ways to improve the models. We could considers more variables that could lead expenditures to be higher or lower including number of workers, supplies, time of the year. In addition, we would collect more data from different cities in New York in an expanded time range.    
\hfill \break

\clearpage
\newpage
\noindent \Large{{\bf Appendix A: Supplemental Tables}}

\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE>>=

stargazer(ny2 %>% dplyr::select(wealth, pop, pint, dens, income, growr), 
          title = "Summary Statistics for all numerical independent features", 
          label="descrips",
          table.placement = "H")

@
\end{center} 

\begin{center}
<<echo = FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=

reg_table <- bind_rows(fit1_summary, fit2_summary, fit3_summary, fit4_summary) %>% 
  as.data.frame() %>% 
  xtable(digits = 4,
         caption = "Regression validation metrics including MSE, R-squared adjusted, and AIC",
         label = "reg_vali_metric",
         table.placement="H")

align(reg_table) <- "rp{2in}llll"

print(reg_table)

@
\end{center}

\begin{center}
<<echo = FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=

xtable(fit4, 
       caption = "Summary Regression of Model 4", 
       label = "reg_summary_4",
       table.placement="H")

@
\end{center}

\begin{center}
<<echo = FALSE, message=FALSE, error=FALSE, warning=FALSE, results = 'asis'>>=

## identify the outlier in residual vs predicted plot 
## extremely large wealth and dens 
## extremely low grow rate 
set2 %>% 
  mutate(index = seq(1, nrow(set2))) %>% 
  filter(rstudent == min(rstudent) | index %in% c(60, 83, 100, 179, 225)) %>%
  dplyr::select(obs, expen, wealth, pop, pint, income, index) %>% 
  xtable(caption = "Outlier Obsevation", 
       label = "outlier_obs",
       table.placement="H")

@
\end{center}


\clearpage
\newpage
\noindent \Large{{\bf Appendix B: Supplemental Figures}}

\begin{figure}[h!] 
\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.width=10, fig.height=8>>=

p1 <- ScatterPlotFunction(set2, "lpop", "Log-Population", "lm")
p2 <- ScatterPlotFunction(set2, "lpint", "% Log Intergovernmental Funds", "lm")
p3 <- ScatterPlotFunction(set2, "ldens", "Log-Density", "lm")
p4 <- ScatterPlotFunction(set2, "lgrowr", "Log-Growth Rate", "lm")

grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)

@
\caption{Exploratory Plot after Log-Transformation and Subsetted Data 1 with linear regression line in red: 1: Log-Expenditures vs Log-Population, 2: Log-Expenditures vs Log-Intergovernmental FUnds, 3: Log-Expenditures vs Log-Density, and 4: Log-Expenditures vs Log- Growth Rate.}
\label{sec2-explore}
\end{center} 
\end{figure}


\begin{figure}[h!] 
\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE>>=

## Influence plot: studentized residuals vs. hat matrix diagonals (leverage) with bubbles a function of Cook's D
## Interactive, so can click to identify high leverage/influential/outlying points
influencePlot(fit_final, id.method="identify", 
              main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )

@
\caption{Plot of inluential points of studentized residuals vs hat values.}
\label{influential-points}
\end{center} 
\end{figure}

\begin{figure}[h!] 
\begin{center}
<<results='asis', echo=FALSE, message=FALSE, error=FALSE, warning=FALSE>>=

# All encompansing R default regression model diagnostics
par(mfrow=c(2,2))
plot(fit_final)
par(mfrow=c(1,1))

@
\caption{Diagnostic plots}
\label{diag-plot2}
\end{center} 
\end{figure}

\clearpage
\newpage
\noindent \Large{{\bf Appendix C: R Code}}
\lstinputlisting[language=R, caption = Appendix of Code]{R/dar1-codes.R}


\end{document}






